multi-cpu-scheduling
single- and multiprocessor is mainly around the use of hardware caches and how data is shared across processors.

복습하자면,cashe는 주로 association memory다.
main memory의 주소일부를 key로 가지고 해당 데이터를 value로 가지며 key값으로 검색하는게 O(1)

Cache Coherence(캐시 일관성) is the problem that arises when multiprocessor system processes need a copy of the same memory block.

캐시에 있는 데이터가 원본과 달라지는 문제

Locks are required to atomically update the data structure.

Cache affinity(캐시 선호도)(하드웨어 레벨 프로토콜인듯)
SQMS:single-queue multiprocessor scheduling
flaws(결함)of sqms:
scalability(확장성):
동일 lock을 전체가 사용함.
Cache Affinity:
Because each CPU simply takes the next job from the globally shared queue, each job ends up bouncing from CPU to CPU, which is contrary to cache affinity.
affinity mechanism to try to keep processes on the same CPU if possible. 

Multi-Queue Scheduling:
The scheduling framework in MQMS consists of multiple scheduling queues. 
Each queue will likely use a different scheduling technique.
When a job is entered into the system, it is placed on exactly one scheduling queue according to some rule (e.g., random, or 
picking one with fewer jobs than others).

Then, each component is scheduled primarily independently, so there are no concerns with information sharing and synchronization.

MQMS should be more scalable than SQMS. MQMS also supports cache affinity. Jobs stay on the same CPU, allowing them to reuse cached items.

Handling Load Imbalance
migration:moving jobs between CPUs
Work stealing:
a queue that is low on jobs occasionally peeks into another queue, to determine how full it is


Dynamic Relocation
base and bounds, which is also called dynamic relocation.

Each CPU requires two hardware registers: one register is called the base while the other is called the bounds

The base-and-bound pair allows the system to place the address space wherever it wants in physical memory. The register pair also ensures that the process only has access to its own address space.

virtual address + base = physical address

Address Translation
Each processor has something called the memory management unit 

Hardware Support
Privileged (Kernel) Mode
This prevents user applications from performing privileged operations.
Base & Bounds Registers
This pair of registers is used to store required information for the translation process.
Address Translation and Verification
Circuitry is required to perform the translations and then check limits.
Update Bounds (Privileged Instruction)
The OS has to be able to set these values before allowing a user program to run.
Register Exception Handlers
OS must have the ability to tell the hardware what code to run in the event of an exception.
Raise Exceptions
OS needs to raise exceptions when a process tries to perform an illegal operation (privileged instruction, out of bounds memory, etc.).

All of this is done using a limited direct execution strategy

This lesson applied what we know about limited direct execution to virtual memory through the use of address translation.
Address translation permits the OS to regulate every memory access made by a process by keeping them within its address space.
Base and bounds virtualization, also known as dynamic relocation, protects against memory references outside a process’s address area.
Internal fragmentation results from the limitation of placing an address space in a fixed-sized slot even there may be enough sufficient physical memory for more processes.

you simply wait for something (i.e., an “event”) to happen; when it does, you determine what
type of event it is and perform the minimal work required (which may
include making I/O requests or scheduling other events for future handling,
among other things).

The main loop simply waits for something to happen, and then processes each event one by one

one event is handled at a time, there is no need for locks to be acquired or released;
the event-based server cannot be interrupted by another thread because it
is single threaded.

asynchronous I/O to get around
this limitation. This is a new technique for sending I/O requests to the disk
system. Applications can use these interfaces to send an I/O request and
swiftly return control to the caller before the I/O is completed;


. In thread-based
programs, state is already on the thread stack when an asynchronous I/O is
issued, so there’s no need for the event handler to package up state so the
following handler can use it after the I/O has been completed. This effort is
referred to as manual stack management by Adya et al., and it is essential
to event-based programming.

simply store the necessary information to complete
processing of this event in some data structure; when the event occurs (i.e.,
when the disk I/O completes), search up the required information and
handle the event.

node 가 single event loop기반 서버. 시간이 걸리는건 하위 워커쓰레드에 주고 처리. IO처럼. Promise가 처리상태정보 가지는것처럼 똑같이 필수적인 정보가 해당 핸들러에 저장되어있어야.