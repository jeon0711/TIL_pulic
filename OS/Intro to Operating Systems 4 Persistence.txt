The CPU is connected to the system’s main memory through a memory bus or connection.
A bus is a system for transferring data between components inside a computer or between computers:
Some devices, like graphics and high performance I/O devices are connected to the system using a general I/O bus like a PCI.
Peripheral buses like SCSI, SATA, and USB are used to connect slower devices like disks, mice, and keyboards.

Instead of constantly polling the device, the OS can use an interrupt to:
Send a request
Put the calling process to sleep, and
Switch the context to another job.

When the I/O request is finished, it sends a hardware interrupt and makes the CPU go into the OS to a specific interrupt handler. This handler is OS code that will complete the request, wake up the process that’s waiting for I/O to finish, and lets it continue about its merry way.

Direct Memory Access (DMA) is our answer to this problem. A DMA engine is a system component that handles transfers between devices and main memory without relying so much on the CPU.

The OS tells the DMA engine where and how much data to copy and what device to send data to.
Now, the OS is finished with the transfer and can go on to other tasks.
The DMA engine raises an interrupt when it’s finished, letting the OS know that the transfer is done.

Device communication is generally done in two ways:
Having explicit I/O instructions that define how the OS delivers data to specific device registers.(직접명령)

Memory-mapped I/O is the second method of interacting with devices.

Explicit I/O - Contains instructions that describe how the OS delivers data to specific device registers.

Memory-mapped I/O - Device registers are accessible in the same way as if they were memory addresses.

Device Driver

Device interface functionalities are wrapped within this piece of software called a device driver.

a file system (or application) doesn’t care about disk class. It just sends read and write requests to the generic block layer, which routes them to the appropriate driver.

Certain programs can read and write blocks directly without needing the file abstraction. Most systems support low-level storage management applications using this interface.

harddisk drives부터
-byte blocks) making up the drive. Each one can be read or written to. It’s like an array of n
 sectors, with an address space ranging from 0
 to n−1.

Now that we have a model of the disk, we can analyze its performance. We can represent Disk Access Time as:
TI/O=Tseek+Trotation+Ttransfer
 
Disk Response Time is the average time a request spends waiting for an I/O operation. The average response time is the average response time across all requests.
The rate of I/O (  RI/O
 ), which is often used to compare drives, is computed from the formula below:
RI/O=SizeTransferTI/O

Storage virtualization is based on two main ideas: the file and the directory.
A file is a group of bytes that can be read or written. Each file has a low-level name in the form of an inode number, that users don’t see very often. The file system makes sure that the original file data is always kept on the disk.
In a directory, the user-readable name and the low-level name are listed in pairs.

A program can create a new file by using open() and passing it the O_CREAT flag. The code to the left creates aFile in the current working directory.
The open() call accepts several flags. here:
O_CREAT - creates the file
O_WRONLY - locks it,
O_TRUNC - truncates it to zero bytes, erasing any existing content
S_IRUSR|S_IWUSR - permissions are set to allow the owner to read and write to the file.

open() returns a file descriptor

The open file table shows us the structures of these files as well as the system’s currently open files.

The private descriptor array of each process is linked to a shared open file table entry that connects to the underlying file-system inode. The reference count for file table entries shared by two processes increases until both processes exit the file.
(각각의 프로세스에 있는 filedescriptor는 동일한 파일 참조시 동일한 openfile table을 참조한다)

We expect a file system to keep certain information, called metadata, about each file it stores. To see a file’s metadata, you can use the stat() or fstat() system functions.

A file’s metadata includes information like:
The file’s size in bytes,
Inode number,
Ownership information
When the file was viewed or modified.

struct stat {
dev_t st_dev;         // ID of device containing file
ino_t st_ino;         // inode number
mode_t st_mode;       // protection
nlink_t st_nlink;     // number of hard links
uid_t st_uid;         // user ID of owner
gid_t st_gid;         // group ID of owner
dev_t st_rdev;        // device ID (if special file)
off_t st_size;        // total size, in bytes
blksize_t st_blksize; // blocksize for filesystem I/O
blkcnt_t st_blocks;   // number of blocks allocated
time_t st_atime;      // time of last access
time_t st_mtime;      // time of last modification
time_t st_ctime;      // time of last status change
};
We can use the stat command-line tool to learn about a file.
stat filename으로 메타데이터 조회가능

Directory data is considered metadata, so you can only update a directory by creating files, directories, or other things within it. This is how the file system makes sure directory contents are correct.

The mkdir() call can create a directory from within an existing program. The mkdir program can create such a directory. The code below creates a basic directory called downloads with the mkdir program.

Instead of opening a directory as a file, the ls program uses three functions:
opendir()
readdir()
closedir()
We can see from the program to the left that ls is basically a loop that reads one directory entry at a time, printing out the name and inode number of each file in the directory.

struct dirent {
  char d_name[256];        // filename
  ino_t d_inode;             // inode number
  off_t d_offset;             // offset to the next dirent
  unsigned short d_recordlen; // length of this record
  unsigned char d_type;    // type of file
};

link() creates a new name in the directory and refers it to the same inode number as the original file.

Making a file completes two tasks by
Creating an inode structure that will track the file’s metadata, and
Linking that file to a human-readable name to be put in a directory.

The original file name and the new file name are both links to the underlying metadata about the file stored in inode number

When the file system unlinks a file, it checks the inode number’s reference count or link count. The reference count keeps track of how many files have been linked to this inode.

A symbolic link, or soft link is similar to creating a hard link, but a bit different. A symbolic link is a different type of file. Just like regular files and directories, symbolic links are a third type of file that the system recognizes.

 File systems frequently have a broader set of techniques for varying levels of sharing.
The first type is the UNIX permission bits.
 
Permissions are divided into three categories:
what the file’s owner can do,
what a group can do, and
what anyone (known as other) can do.

A process has to first ask the operating system for permission to access a file. A file descriptor is returned if permission is given with the intent to enable read or write access.
Each file descriptor relates to an entry in the open file table. A file’s current offset and other important information are tracked in this entry.
Processes can use lseek() to modify the current offset, allowing random access to different regions of the file.
A process must use fsync() or similar functions to update persistent data. However, doing so correctly while keeping high performance is difficult.
You can use hard links or symbolic links to have several human-readable names point to the same underlying file. Consider their strengths and disadvantages before using them. Remember that removing a file only unlinks it from the directory hierarchy.
Most file systems allow you to turn sharing on and off. Permissions bits give a basic method for these controls. Access control lists provide more precise control over who can access and change data.

crash sinario는
data block,inode,bitmap중 하나,둘만 써지고 나머지는 실패할 수 있다. 

Superblock: fsck checks the superblock by comparing the file system size to the allotted blocks. Finding corrupt superblocks is the goal. In this case, the system (or administrator) can use a backup superblock.
Free blocks: Then fsck traverses the inodes, indirect blocks, double indirect blocks, etc. to determine the file system’s current block allocation. It relies on inode information to produce correct allocation bitmaps, thus any discrepancy between bitmaps and inodes is addressed. Also, all inodes are checked for use in the inode bitmaps.
Inode state: Every inode is checked for damage. For example: fsck checks each inode’s type field (e.g., regular file, directory, symbolic link, etc.). Unresolved inode field issues are dealt with by fsck and the inode bitmap is refreshed.
Inode links: fsck counts the links in each inode. A folder reference (or link) counts the number of folders that contain a file reference (or link). Each file and directory in the file system has its own link count, which is validated by fsck. It is necessary to fix the inode count if the newly calculated count does not match. An allocated inode is moved to the lost+found directory when it is discovered.
Duplicates: fsck checks for duplicate block references in inodes. Delete an obvious defective inode. Cloning the pointed-to block would provide each inode its own copy.
Bad blocks: Faulty block pointers are detected while scanning the pointer list. An address larger than the partition size is considered “bad”. fsck simply removes the pointer from the inode or indirect block.
Directory checks: fsck doesn’t understand user files, but directories contain file system information. For each directory entry, fsck ensures that the inode referenced is allocated, and that no directory is linked to more than once in the hierarchy.

Scanning a huge disk volume to find all allocated blocks and read the directory tree may take minutes or hours. fsck performance became prohibitive as disk size and RAID adoption expanded (despite recent enhancements).

Write-ahead logging, or journaling

With write-ahead logging, before an update is made on the disk, a note is made somewhere else on the disk stating what is about to happen.
If a crash happens during a structure overwrite, instead of scanning the entire disk, you can just refer to the note you wrote and try again. Journaling adds work during updates to reduce recovery effort.

With Linux ext3, a well known journaling file system, the disk is separated into block groups, and each block group has an inode bitmap, data bitmap, inodes, and data blocks. The new key structure is the journal, which takes up little space in the partition or elsewhere.

Five blocks are used here. TxB contains the final addresses of blocks I[v2], B[v2], and Db (the pending file system update) and a transaction identifier (TID).

Then comes physical logging, three blocks of the update’s specific physical content. The last block (TxE) carries the transaction ID.

Once this transaction is safely placed on disk, we checkpoint the file system and overwrite the existing structures. To do this, we write I[v2], B[v2], and Db to disk. So our initial operation sequence is:
Journal write: Write the transaction to the log, including a transaction-begin block, all pending data and metadata modifications, and a transaction-end block.
Checkpoint: Update the pending information and data in the file system.

We start with TxB, I[v2], B[v2], Db, and TxE. After these writes, we checkpoint I[v2], B[v2], and Db to their ultimate destinations on disk.

It uses two-step transactional writing to avoid this. It first writes all blocks except TxE to the journal. The diary will then look like this (if we keep appending):
After that, the file system writes the TxE block, leaving the journal in this safe state:

A file system can use the journal to recover from a crash.
If the crash happens before the transaction is successfully logged, the pending update is skipped.

It is possible to recover updates if the file system crashes after the transaction commits but before the checkpoint.

The journal superblock stores enough information to identify which transactions have not yet been checkpointed. This allows for faster recovery and cyclic log usage.
We’ll add another step to our protocol:
Journal write: Write the contents of the transaction (TxB and the update) to the log.
Journal commit: Write the transaction commit block (TxE) to the log; wait for it to finish.
Checkpoint: Update the file system content to their final destinations.
Free: Update the journal superblock to label the transaction free.

Unlike metadata journaling, ordered journaling does not write user data to the notebook

For metadata-only journaling, the data blocks should be written first.
File systems like Linux ext3 write data blocks before metadata. The protocol is as follows:
Data write: At final location, write data; wait for completion (waiting is optional; details below).
Journal metadata write: Write the begin block and metadata to the log; wait for writes to complete.
Journal commit: Write the transaction commit block (including TxE) to the log; wait for the write to finish.
Checkpoint metadata: Write the metadata update to its final file system location.
Free: Later, mark the transaction free in journal superblock.

Soft Updates are another way to maintain metadata consistency. For example, it writes a pointed-to data block to disk before the inode that points to it, so the inode never points to garbage.

Copy-on-write (COW) is also utilized in several file systems, notably Sun’s ZFS. Not overwriting existing files or directories, but simply updating unused storage space. The COW file system updates the root structure with fresh structure references.

Backpointer-based consistency (BBC) is another method. Writing is not ordered. Every block in the system gets a back pointer. The file system can tell if a file is consistent by looking at the forward pointer, or address in the inode or direct block. If so, everything has reached disk safely, and the file is consistent; if not, an error is returned.

With an extended form of the transaction checksum and a few other techniques, the optimistic crash consistency strategy issues as many writes to disk as possible while detecting discrepancies.

We introduced the issue of crash consistency and a few of its possible solutions.
On newer computers, the earlier way of generating a file system checker may be too slow. So journaling is now widely used.
In short, journaling reduces recovery time from O(disk volume size) to O(log volume size), greatly speeding up post-crash recovery.
Journaling can take several forms; the most common is ordered metadata journaling, which minimizes traffic to the journal while maintaining sufficient consistency guarantees for both file system information and user data.
Solid user data guarantees are undoubtedly one of the most critical things to provide; however, recent research shows that this field is still evolving.